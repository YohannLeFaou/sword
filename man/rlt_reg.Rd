% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rlt_reg.R
\name{rlt_reg}
\alias{rlt_reg}
\title{Fit a RLT model and compute predictions of expectations for \code{phi}\eqn{(T)}}
\usage{
rlt_reg(y_var, delta_var, x_vars, train, test = NULL, phi = function(x) {   
   x }, phi.args = list(), max_time = NULL, rlt_obj = T,
  ev_methods = c("concordance", "weighted"), bandwidths = NULL,
  types_w_ev = c("KM"), max_w_ev = 20, mat_w = NULL,
  y_no_cens_var = NULL, ntree = 100, minleaf = 5, maxdepth = 6,
  mtry = NULL, reinforcement = T, ...)
}
\arguments{
\item{y_var}{A character string which gives the name of the \eqn{Y} variable}

\item{delta_var}{A character string which gives the name of the \eqn{\delta} variable (this variable
should be binary : 1 = non censored, 0 = censored)}

\item{x_vars}{A vector of character strings which gives the names of the explanatory variables}

\item{train}{A data.frame of training observations. It must contain the column names \code{y_var},
\code{delta_var} and \code{x_vars}}

\item{test}{A data.frame of testing observations (default = \code{NULL})}

\item{phi}{A function to be applied to \code{y_var}}

\item{phi.args}{A list of additional parameters for the function \code{phi} (default = NULL).
See \emph{Examples} for a use case}

\item{max_time}{A real number giving a threshold for \code{y_var} (default = \code{NULL}).
If \code{NULL}, then \code{max_time} is set to the maximum non censored observation
of \code{y_var} among the training set. We note \eqn{T' = min(T,} \code{max_time}\eqn{)}}

\item{rlt_obj}{A boolean which indicates if the RLT model fitted to the training data should
be returned (default = \code{TRUE})}

\item{ev_methods}{A vector of character strings which gives the methods that should be
used for the evaluation of the model (default = \code{c("concordance","weighted")}).
Possible choices are \code{"concordance"}, \code{"weighted"} and \code{"group"}. Multiple choices are possible.
See \emph{Details - Evaluation criteria} for more information}

\item{bandwidths}{A vector of real numbers for the bandwidths to use for the model
evaluation if \code{"group"} is used
as an \code{ev_methods} (default = \code{NULL} : set to 50 if \code{"group"} in \code{ev_methods}).
Only used if \code{"group"} is used as \code{ev_methods}.
See \emph{Details - Evaluation criteria} for more information}

\item{types_w_ev}{A vector of character strings which gives the types of weights to be used for IPCW
(Inverse Probability of Censoring Weighting) in the model evaluation (default = \code{c("KM")} (Kaplan Meier)).
Possible choices are \code{"KM"}, \code{"Cox"}, \code{"RSF"} and \code{"unif"}. Set to \code{colnames(mat_w)}
if \code{mat_w} is provided. See
\emph{Details - Evaluation criteria} for more information}

\item{max_w_ev}{A real number which gives the maximum admissible ratio
for the IPC weights (default = 1000).
See \emph{Details - Evaluation criteria} for more information}

\item{mat_w}{A matrix to provide handmade IPC weights for the model evaluation (default = \code{NULL}).
\code{mat_w} should satisfied \code{nrow(mat_w) = nrow(train) + nrow(test)} and a column
should correspond to a type of weights (multiple columns are possible).
Column names of \code{mat_w} may be used to specify names
for the provided weights (by default names will be "w1", "w2", ...)}

\item{y_no_cens_var}{A character string which gives the name of the non censored \code{y_var}
(default = NULL).
To be used only in the context of simulated data where full about is available.}

\item{ntree}{A positive integer which gives the number of trees to grow
in the forest (default = \code{100}).}

\item{minleaf}{A positive integer indicating the minimum number of observations
that must be present in a (terminal) leaf (default = \code{5}).}

\item{maxdepth}{A positive integer indicating the maximum number of layers
in individual trees (default = \code{6}).}

\item{mtry}{A positive integer indicating the number of random variables
to draw at each node for the split selection (default = \code{NULL}).
If \code{NULL}, \code{mtry} is set to \code{floor(sqrt(length(x_vars)))} by default.}

\item{reinforcement}{A boolean which specifies if reinforcement in RLT shloud be used for
split selection}

\item{...}{Additional parameter that may be pass to the \code{\link[RLT]{RLT}}
function (package \emph{RLT})}
}
\value{
A list with the following elements :
\item{pred_train}{The vector of the predicted values for \code{phi}\eqn{(T')}
(with \eqn{T' = min(T, } \code{max_time}\eqn{)}) for the observations of the train set}
\item{pred_test}{The vector of the predicted values for
\code{phi}\eqn{(T')} for the observations of the test set (require \code{test} != \code{NULL})}
\item{perf_train}{The list with the values for the evaluation criteria computed on the train
set}
\item{perf_test}{The list with the values for the evaluation criteria computed on the test
set (require \code{test} != \code{NULL}))}
\item{surv_train}{The matrix which contains the estimated values of the survival curves at
\code{time_points} (with the Cox model), for the observations of the train set}
\item{surv_test}{The matrix which contains the estimated values of the survival curves at
\code{time_points}, for the observations of the test set (require \code{test} != \code{NULL})}
\item{time_points}{The vector of the time points where the survival curves are evaluated}

\item{mat_w_train}{The matrix which contains the values of the weights used for the
\code{"weighted"} criteria, for the observations of the train set}

\item{mat_w_test}{The matrix which contains the values of the weights used for the
\code{"weighted"} criteria, for the observations of the test set}
\item{n_w_ev_modif_train}{The vector giving the number of train weights modified due to
\code{max_w_ev}}

\item{n_w_ev_modif_test}{The vector giving the number of test weights modified due to
\code{max_w_ev}}

\item{rlt_obj}{The obj returned by the \code{RLT} function}

\item{max_time}{The real number giving the threshold used by the model}

\item{cens_rate}{The real number giving the rate of censoring
of \eqn{T'}, computed on the concatenation of \code{train} and \code{test}}

\item{train}{The data.frame of the train data provided as arguments, plus columns :
\eqn{Y' = min(Y,} \code{max_time} \eqn{)}, \eqn{\delta' = 1_{T' \le C}}
and \code{phi}\eqn{(T')} }
\item{test}{The data.frame of the test data provided as arguments, plus columns :
\eqn{Y' = min(Y,} \code{max_time} \eqn{)}, \eqn{\delta' = 1_{T' \le C}}
and \code{phi}\eqn{(T')} }

\item{phi}{See \emph{Argument}}

\item{phi.args}{See \emph{Argument}}

\item{x_vars}{See \emph{Argument}}

\item{max_w_ev}{See \emph{Argument}}
}
\description{
\code{rlt_reg} is a benchmark model we use in [Gerber et al. (2018)].
To model the variable \code{phi}\eqn{(T)}, where \eqn{T} is a right censored time and
\code{phi} is a given function, we first
fit a RLT (Reinforcement Learning Trees) model to the data to estimate the survival function
of \eqn{T} given the covariates. Then,
we deduce an estimator of \code{phi}\eqn{(T)} by integration of the function \code{phi} with respect
to the estimated survival function. Different methods are available to assess the quality of fit of
\code{rlt_reg}. \code{rlt_reg} is a wrapper for the \code{\link[RLT]{RLT}}
function\cr \cr
The notations we use are :
\itemize{
\item \eqn{C} : Censoring variable
\item \eqn{Y = min(T, C)}
\item \eqn{\delta = 1_{T \le C}}  (delta)
}
}
\details{
\itemize{
\item \emph{Evaluation criteria}

The quality of fit may be assess throught three different criteria. There are two main
criteria : \code{"weighted"} and \code{"concordance"}, and one criteria that is expimental : \code{"group"}.

\itemize{

\item \code{"weighted"} : the weighed criteria is described in ยง? of [Gerb. et al.]. This criteria aims
to estimate the quadratic error of the model in the context of right censoring. It has the form
\eqn{\sum_i W_i  (y_i - \hat{y}_i)^2} where \eqn{(y_i)i} are the censored targets of the model, \eqn{(W_i)i}
are the IPC weights, and \eqn{(\hat{y}_i)i} are the predictions made.

The \code{types_w_ev} argument allows the use of four kinds of IPC weights :
\code{"KM"}, \code{"Cox"}, \code{"RSF"} and \code{"unif"}. The first three types of weights correspond
to different ways to estimate the survival function of the censoring. On the other hand, \code{"unif"}
corresponds to \eqn{W_i = 1} for all i.

Since the IPC weights may take too large values in some situation, \code{max_w_ev} allows
to threshold the weights \eqn{(W_i)i} so that the ratio between the largest and the smallest weights doesn't
exceed \code{max_w_ev}. If \eqn{W_max} is the maximum weight, considered weights are then
\eqn{min(W_i, W_max) / ( \sum_i min(W_i, W_max) ) }

You can also manually provide weights to be used for IPCW with the argument \code{mat_w} (those
weights will also be threshold w.r.t. \code{max_ration_weights_eval}). \code{mat_w} should be a
matrix satisfying \code{nrow(mat_w) = nrow(train) + nrow(test)}, any numbers of
columns may be provided and then each column of the matrix corresponds to a type of weights.
Columns name of the matrix are taken as names for the different types of weights. If there is no
column name, then default names are "w1", "w2', ...


\item \code{"concordance"} : The concordance is a classical measure of performance when modelling
censored variables. It indicates if the order of the predicted values of the model is similar to
the order of the observed values. The concordance generalizes the Kendall tau to the censored case.


\item \code{"group"} : This is an experimental criteria that we didn't mention in [Gerb. et al.]. Here,
the idea to take the censoring into account is to measure errors given groups of observations and
not single observations. First, the test sample is ordered w.r.t. the predicted values of the
model. Second, respecting this order the test sample is splited into groups of size \code{v_bandwidht[1]}, or
\code{v_bandwidht[2]}, etc ... (each bandwidth in \code{v_bandwidht} corresponds to a different
score \code{"group"}).

Then, inside a group, an estimator of the survival function of \eqn{T} may be obtained by
Kaplan Meier, and we can deduce an estimator of \code{phi}\eqn{(T)} by integration. This estimator
of \code{phi}\eqn{(T)} may be
viewed as an "empirical" value of \code{phi}\eqn{(T)} inside the group.

On the other other hand, each observation of a group is associated to a prediction of \code{phi}\eqn{(T)}.
The prediction for the group may be defined as the mean of the predictions of the observations
inside the group.

The resulting group scores correspond to the classical quality of fit criteria (e.g. quadratic error,
Kendall tau, Gini index) but taken on groups and not on single observations.

The \code{"group"} criteria is interesting in the context of big database, in which sufficient
number of groups are available. This criteria has a high variance if applied to small test sample.

}
}
}
\references{
Gerber, G., Le Faou, Y., Lopez, O., & Trupin, M. (2018). \emph{The impact of churn on
prospect value in health insurance, evaluation using a random forest under random censoring.}
\url{https://hal.archives-ouvertes.fr/hal-01807623/}
}
\seealso{
\code{\link[RLT]{RLT}}, \code{\link{predict_rlt_reg}}
}
