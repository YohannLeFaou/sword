% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sw_reg.R
\name{sw_reg}
\alias{sw_reg}
\title{Fit classical regression model (GAM, RF) on right censored data using IPCW}
\usage{
sw_reg(y_var, delta_var, x_vars, train, test = NULL, type_reg = "RF",
  type_w = "KM", phi = function(x) {     x }, phi.args = list(),
  max_time = NULL, sw_reg_obj = T, cens_mod_obj = T,
  ev_methods = c("concordance", "weighted"), bandwidths = NULL,
  types_w_ev = "KM", max_w_mod = NULL, max_w_ev = 1000, mat_w = NULL,
  y_no_cens_var = NULL, mode_sw_RF = 1, ntree = 100, minleaf = 5,
  maxdepth = 6, mtry = NULL, ...)
}
\arguments{
\item{y_var}{A character string which gives the name of the \eqn{Y} variable}

\item{delta_var}{A character string which gives the name of the \eqn{\delta} variable (this variable
should be binary : 1 = non censored, 0 = censored)}

\item{x_vars}{A vector of character strings which gives the names of the explanatory variables}

\item{train}{A data.frame of training observations. It must contain the column names \code{y_var},
\code{delta_var} and \code{x_vars}}

\item{test}{A data.frame of testing observations (default = \code{NULL})}

\item{type_reg}{A character string giving the regression algorithm to use
in the model (default = \code{"RF"}). Other possible value is "gam".}

\item{type_w}{A character string giving the type of IPC weights used to
train the regression model (default = \code{"KM"}). Other possible values are "Cox", "RSF"
and "unif". Set to \code{colnames(mat_w)[1]}
if \code{mat_w} is provided.}

\item{phi}{A function to be applied to \code{y_var}}

\item{phi.args}{A list of additional parameters for the function \code{phi} (default = NULL).
See \emph{Examples} for a use case}

\item{max_time}{A real number giving a threshold for \code{y_var} (default = \code{NULL}).
If \code{NULL}, then \code{max_time} is set to the maximum non censored observation
of \code{y_var} among the training set. We note \eqn{T' = min(T,} \code{max_time}\eqn{)}}

\item{sw_reg_obj}{A boolean which indicates if the random forest
model fitted to the training data should
be returned (default = \code{TRUE})}

\item{cens_mod_obj}{A boolean which indicates if the
model fitted to the censoring variable to compute the weights
("KM", "Cox" or "RSF") used for training should
be returned (default = \code{TRUE})}

\item{ev_methods}{A vector of character strings which gives the methods that should be
used for the evaluation of the model (default = \code{c("concordance","weighted")}).
Possible choices are \code{"concordance"}, \code{"weighted"}
and \code{"group"}. Multiple choices are possible.
See \emph{Details - Evaluation criteria} for more information}

\item{bandwidths}{A vector of real numbers for the bandwidths to use for the model
evaluation if \code{"group"} is used
as an \code{ev_methods} (default = \code{NULL} : set to 50 if \code{"group"} in \code{ev_methods}).
Only used if \code{"group"} is used as \code{ev_methods}.
See \emph{Details - Evaluation criteria} for more information}

\item{types_w_ev}{A vector of character strings which gives the
types of weights to be used for IPCW
(Inverse Probability of Censoring Weighting) in the model evaluation
(default = \code{c("KM")} (Kaplan Meier)).
Possible choices are \code{"KM"}, \code{"Cox"}, \code{"RSF"} and \code{"unif"}. Set to
\code{colnames(mat_w)}
if \code{mat_w} is provided. See
\emph{Details - Evaluation criteria} for more information}

\item{max_w_mod}{A real number which gives the maximum admissible ratio
for the IPC weights (default = NULL : then set to \code{floor(sqrt(nrow(train))/2)})
used in model fitting.
See \emph{Details - Evaluation criteria} for more information}

\item{max_w_ev}{A real number which gives the maximum admissible ratio
for the IPC weights (default = 1000) used in model evaluation.
See \emph{Details - Evaluation criteria} for more information}

\item{mat_w}{A matrix to provide handmade IPC weights for the model
evaluation (default = \code{NULL}).
\code{mat_w} should satisfied
\code{nrow(mat_w) = nrow(train) + nrow(test)}
and a column should correspond to a type of weights
(multiple columns are possible).
Column names of \code{mat_w} may be used to specify names
for the provided weights (by default names will be "w1", "w2", ...)}

\item{y_no_cens_var}{A character string which gives the name of the
non censored \code{y_var} (default = \code{NULL}).
To be used only in the context of simulated data where full about is available}

\item{mode_sw_RF}{An integer (\code{1} or \code{2}) which specifiy the type of weighted
random forest to grow : \code{1} = wRF1, \code{2} = wRF2 or wRF3 (default = \code{1}).
See \emph{Details - Random Forest modes} for more information.
Only used if \code{type_reg = "RF"}}

\item{ntree}{A positive integer which gives the number of trees to grow
in the forest (default = \code{100}).}

\item{minleaf}{A positive integer indicating the minimum number of observations
that must be present in a (terminal) leaf (default = \code{5}).}

\item{maxdepth}{A positive integer indicating the maximum number of layers
in individual trees (default = 6).}

\item{mtry}{A positive integer indicating the number of random variables
to draw at each node for the split selection (default = \code{NULL}).
If \code{NULL}, \code{mtry} is set to \code{floor(sqrt(length(x_vars)))} by default.

Warning (Exception to he latter statement) : if \code{mode_sw_RF = 2},
\code{mtry} is set to \code{length(x_vars)}
and can not be modified}

\item{...}{Additional parameter that may be pass to the regression algorithm used
(see \emph{Details - Additional parameters})}
}
\value{
A list with the following elements :

\item{pred_train}{The vector of the predicted values for \code{phi}\eqn{(T')}
(with \eqn{T' = min(T, } \code{max_time}\eqn{)}) for the observations of the train set.
See \emph{Details - Random Forest modes} for more information}

\item{pred_test}{The vector of the predicted values for
\code{phi}\eqn{(T')} for the observations of the test set (require \code{test} != \code{NULL}).
See \emph{Details - Random Forest modes} for more information}

\item{perf_train}{The list with the values for the evaluation criteria computed on the train
set}

\item{perf_test}{The list with the values for the evaluation criteria computed on the test
set (require \code{test} != \code{NULL}))}

\item{w_mod_train}{The vector of the weights used to train the model,
after applying \code{max_w_mod} and normalising}

\item{n_w_mod_modif_train}{The vector giving the number of train weights modified due to
\code{max_w_mod}}

\item{mat_w_train}{The matrix which contains the values of the weights used for the
\code{"weighted"} criteria, for the observations of the train set}

\item{mat_w_test}{The matrix which contains the values of the weights used for the
\code{"weighted"} criteria, for the observations of the test set}

\item{sum_w_train}{The sum of the gross weights for the train data,
before applying \code{max_w_ev} and normalising}

\item{sum_w_test}{The sum of the gross weights for the test data,
before applying \code{max_w_ev} and normalising}

\item{n_w_ev_modif_train}{The vector giving the number of train weights modified due to
\code{max_w_ev}}

\item{n_w_ev_modif_test}{The vector giving the number of test weights modified due to
\code{max_w_ev}}

\item{sw_RF_obj}{The obj returned by \code{\link[randomForestSRC]{rfsrc}}
(when \code{type_reg = "RF"} and \code{mode_sw_RF = 1})}

\item{sw_gam_obj}{The obj returned by \code{\link[mgcv]{gam}}
(when \code{type_reg = "gam"})}

\item{sw_rpartRF_obj}{The obj returned by \code{\link{rfsrc}}
(when \code{type_reg = "RF"} and \code{mode_sw_RF = 2})}

\item{max_time}{The real number giving the threshold used by the model}

\item{cens_rate}{The real number giving the rate of censoring
of \eqn{T'}, computed on the concatenation of \code{train} and \code{test}}

\item{pred_train_KMloc}{The vector of the predicted values for \code{phi}\eqn{(T')}
for the observations of the train set (require \code{mode_sw_RF = 2}).
See \emph{Details - Random Forest modes} for more information}

\item{pred_test_KMloc}{The vector of the predicted values for \code{phi}\eqn{(T')}
for the observations of the test set (require \code{mode_sw_RF = 2}).
See \emph{Details - Random Forest modes} for more information}

\item{perf_train_KMloc}{The list with the values for the evaluation criteria computed on the train
set (require \code{mode_sw_RF = 2}).
See \emph{Details - Random Forest modes} for more information}

\item{perf_test_KMloc}{The list with the values for the evaluation criteria computed on the test
set (require \code{mode_sw_RF = 2}).
See \emph{Details - Random Forest modes} for more information}

\item{surv_train_KMloc}{The matrix which contains the estimated values of the survival
curves at \code{time_points} (within leaf Kapaln Meier estimator),
for the observations of the train set (require \code{mode_sw_RF = 2})}

\item{surv_test_KMloc}{The matrix which contains the estimated values of the survival
curves at \code{time_points} (within leaf Kapaln Meier estimator),
for the observations of the test set
(require \code{mode_sw_RF = 2})}

\item{time_points}{The vector of the time points where the survival curves
are evaluated (require \code{mode_sw_RF = 2})}

\item{train}{The data.frame of the train data provided as arguments, plus columns :
\eqn{Y' = min(Y,} \code{max_time} \eqn{)}, \eqn{\delta' = 1_{T' \le C}}
and \code{phi}\eqn{(T')}}

\item{test}{The data.frame of the test data provided as arguments, plus columns :
\eqn{Y' = min(Y,} \code{max_time} \eqn{)}, \eqn{\delta' = 1_{T' \le C}}
and \code{phi}\eqn{(T')} }

\item{type_reg}{See \emph{Argument}}

\item{type_w}{See \emph{Argument}}

\item{phi}{See \emph{Argument}}

\item{phi.args}{See \emph{Argument}}

\item{x_vars}{See \emph{Argument}}

\item{max_w_mod}{See \emph{Argument}}

\item{max_w_ev}{See \emph{Argument}}

\item{mode_sw_RF}{See \emph{Argument}}
}
\description{
\code{sw_reg} is the core function of the package.
It implements the method we study in [Gerber et al. (2018)] to adapt regression
algorithms to right censored target variable. Given a right
censored variable \eqn{T}, a
function \code{phi} and covariates \eqn{X}, \code{sw_reg}
aims to estimate \eqn{E[}\code{phi}\eqn{(T)|X]}. The methods is based on the
IPCW (Inverse probability of Censoring Weighting) principle for right
censored variables which is used to compensate for the censoring. Though the method
may generalise to many regression algorithms, \code{sw_reg}
only implements random forest and GAM solutions.
Technicaly, \code{sw_reg} is a wrapper for
\code{\link[randomForestSRC]{rfsrc}} and \code{\link[rpart]{rpart}}(random
forest) and \code{\link[mgcv]{gam}} (GAM). Different methods are available
to assess the quality of fit of \code{rsf_reg}.\cr \cr
The notations we use are :
\itemize{
\item \eqn{C} : Censoring variable
\item \eqn{Y = min(T, C)}
\item \eqn{\delta = 1_{T \le C}}  (delta)
}
}
\details{
\itemize{
\item \emph{Evaluation criteria}

The quality of fit may be assess throught three different criteria. There are two main
criteria : \code{"weighted"} and \code{"concordance"}, and one criteria that is expimental : \code{"group"}.

\itemize{

\item \code{"weighted"} : the weighed criteria is described in §? of [Gerb. et al.]. This criteria aims
to estimate the quadratic error of the model in the context of right censoring. It has the form
\eqn{\sum_i W_i  (y_i - \hat{y}_i)^2} where \eqn{(y_i)i} are the censored targets of the model, \eqn{(W_i)i}
are the IPC weights, and \eqn{(\hat{y}_i)i} are the predictions made.

The \code{types_w_ev} argument allows the use of four kinds of IPC weights :
\code{"KM"}, \code{"Cox"}, \code{"RSF"} and \code{"unif"}. The first three types of weights correspond
to different ways to estimate the survival function of the censoring. On the other hand, \code{"unif"}
corresponds to \eqn{W_i = 1} for all i.

Since the IPC weights may take too large values in some situation, \code{max_w_ev} allows
to threshold the weights \eqn{(W_i)i} so that the ratio between the largest and the smallest weights doesn't
exceed \code{max_w_ev}. If \eqn{W_max} is the maximum weight, considered weights are then
\eqn{min(W_i, W_max) / ( \sum_i min(W_i, W_max) ) }

You can also manually provide weights to be used for IPCW with the argument \code{mat_w} (those
weights will also be threshold w.r.t. \code{max_ration_weights_eval}). \code{mat_w} should be a
matrix satisfying \code{nrow(mat_w) = nrow(train) + nrow(test)}, any numbers of
columns may be provided and then each column of the matrix corresponds to a type of weights.
Columns name of the matrix are taken as names for the different types of weights. If there is no
column name, then default names are "w1", "w2', ...


\item \code{"concordance"} : The concordance is a classical measure of performance when modelling
censored variables. It indicates if the order of the predicted values of the model is similar to
the order of the observed values. The concordance generalizes the Kendall tau to the censored case.


\item \code{"group"} : This is an experimental criteria that we didn't mention in [Gerb. et al.]. Here,
the idea to take the censoring into account is to measure errors given groups of observations and
not single observations. First, the test sample is ordered w.r.t. the predicted values of the
model. Second, respecting this order the test sample is splited into groups of size \code{v_bandwidht[1]}, or
\code{v_bandwidht[2]}, etc ... (each bandwidth in \code{v_bandwidht} corresponds to a different
score \code{"group"}).

Then, inside a group, an estimator of the survival function of \eqn{T} may be obtained by
Kaplan Meier, and we can deduce an estimator of \code{phi}\eqn{(T)} by integration. This estimator
of \code{phi}\eqn{(T)} may be
viewed as an "empirical" value of \code{phi}\eqn{(T)} inside the group.

On the other other hand, each observation of a group is associated to a prediction of \code{phi}\eqn{(T)}.
The prediction for the group may be defined as the mean of the predictions of the observations
inside the group.

The resulting group scores correspond to the classical quality of fit criteria (e.g. quadratic error,
Kendall tau, Gini index) but taken on groups and not on single observations.

The \code{"group"} criteria is interesting in the context of big database, in which sufficient
number of groups are available. This criteria has a high variance if applied to small test sample.

}

\item \emph{Random Forest modes}

modes correspond to different ways to take the weights into account in the random forest :
\itemize{
\item \code{mode_sw_RF = 1} : weights are computed a single time (on the
whole train sample) before the growing of the forest and are passed
to the forest as probabilities of sampling single observations for the bootstrap
of the random forest. This mode corresponds to \emph{wRF1} in
[Gerb. et al.], it internally calls the \code{\link[randomForestSRC]{rfsrc}}
function.
\item \code{mode_sw_RF = 2} : weights are computed \code{ntree} times ; for a given
tree, a bootsrap sample is drawn uniformly with replacement and then weights are
evaluated on the bootstrap sample. The tree growing procedure use then weighted error
as splitting criteria. Two types of predictions are made in this mode : the first
prediction is output as \code{pred_train/test} and it uses the same weights
as those used for training to compute predictions in terminal leafs (\emph{wRF2} in
[Gerb. et al.]). The second prediction is output as \code{pred_train/test_KMloc}
and it makes terminal leafs estimation by using Kaplan Meier to estimate
the within leaf survival function of \eqn{T}.
This mode internally calls the \code{\link[rpart]{rpart}} function.
}

\item \emph{Additional parameters}

\code{sw_reg} allows to pass additional parameters to
the underlying regression algorithm. Depending on \code{type_reg}
and \code{mode_sw_RF}, the wrapped function is as follow :
\itemize{
\item \code{type_reg = "RF"} and \code{mode_sw_RF = 1} : \code{\link[randomForestSRC]{rfsrc}}
\item \code{type_reg = "RF"} and \code{mode_sw_RF = 2} : \code{\link[rpart]{rpart}}
\item \code{type_reg = "gam"} : \code{\link[mgcv]{gam}}
}
For instance in the first case, one may pass to \code{sw_reg}
a parameter that is then passed to \code{\link[randomForestSRC]{rfsrc}}
(e.g. \code{proximity = TRUE})
}
}
\examples{

# ------------------------------------------------
#   Load "transplant" data
# ------------------------------------------------
data("transplant", package = "survival")
transplant$delta = 1 * (transplant$event == "ltx") # create binary var
# which indicate censoring/non censoring

# keep only rows with no missing value
apply(transplant, MARGIN = 2, FUN = function(x){sum(is.na(x))})
transplant_bis = transplant[stats::complete.cases(transplant),]

# plot the survival curve of transplant data
KM_transplant = survfit(formula = survival::Surv(time = futime, event = delta) ~ 1,
                        data = transplant_bis)
plot(KM_transplant)

# ------------------------------------------------
#   Basic call to train a model
# ------------------------------------------------
res1 = sw_reg(y_var = "futime",
                                    delta_var = "delta",
                                    x_vars = setdiff(colnames(transplant_bis),
                                                     c("futime", "delta", "event")),
                                    train = transplant_bis
)
# parameters set by default
res1$type_w
res1$type_reg
res1$max_w_mod
res1$max_w_ev
res1$mode_sw_RF # 1 corresponds to wRF1 in [Gerb. et al.]


# train errors
res1$perf_train

# ------------------------------------------------
#   Training with estimation of test error
# ------------------------------------------------
set.seed(17)
train_lines = sample(1:nrow(transplant_bis), 600)
res2 = sw_reg(y_var = "futime",
                                    delta_var = "delta",
                                    x_vars = setdiff(colnames(transplant_bis),
                                                     c("futime", "delta", "event")),
                                    train = transplant_bis[train_lines,],
                                    test = transplant_bis[-train_lines,],
                                    types_w_ev = c("KM", "Cox", "RSF", "unif"))

print(res2$max_time) # default \\code{max_time} has changed since train set
# is different

# there is a uge overfitting in terms of quadratic errors
print(res2$perf_train)
print(res2$perf_test)

# default parameters for the random forest are
res2$sw_RF_obj$ntree
res2$sw_RF_obj$mtry
res2$sw_RF_obj$nodesize
res2$sw_RF_obj$nodedepth # means there is no depth limit


# -----------------------------------------------------
#   Modify the \\code{max_time} argument & look for
#       the best model under this setting
# -----------------------------------------------------

set.seed(17)
train_lines = sample(1:nrow(transplant_bis), 600)
res30 = sw_reg(y_var = "futime",
                                    delta_var = "delta",
                                    x_vars = setdiff(colnames(transplant_bis),
                                                     c("futime", "delta", "event")),
                                    train = transplant_bis[train_lines,],
                                    test = transplant_bis[-train_lines,],
                                    type_w = "KM", # default value
                                    max_time = 600, # we set \\code{max_time} to 600
                                    types_w_ev = c("KM", "Cox", "RSF", "unif"))
print(res30$perf_test)

# are the other types of weights giving better results ?
## Cox weights
res31 = sw_reg(y_var = "futime",
                                    delta_var = "delta",
                                    x_vars = setdiff(colnames(transplant_bis),
                                                     c("futime", "delta", "event")),
                                    train = transplant_bis[train_lines,],
                                    test = transplant_bis[-train_lines,],
                                    type_w = "Cox",
                                    max_time = 600, # we set \\code{max_time} to 600
                                    types_w_ev = c("KM", "Cox", "RSF", "unif"))
print(res31$perf_test) # slight improvment compared with weights KM

## RSF weights
res32 = sw_reg(y_var = "futime",
                                     delta_var = "delta",
                                     x_vars = setdiff(colnames(transplant_bis),
                                                      c("futime", "delta", "event")),
                                     train = transplant_bis[train_lines,],
                                     test = transplant_bis[-train_lines,],
                                     type_w = "RSF",
                                     max_time = 600, # we set \\code{max_time} to 600
                                     types_w_ev = c("KM", "Cox", "RSF", "unif"))
print(res32$perf_test)

## unif weights
res33 = sw_reg(y_var = "futime",
                                     delta_var = "delta",
                                     x_vars = setdiff(colnames(transplant_bis),
                                                      c("futime", "delta", "event")),
                                     train = transplant_bis[train_lines,],
                                     test = transplant_bis[-train_lines,],
                                     type_w = "unif",
                                     max_time = 600, # we set \\code{max_time} to 600
                                     types_w_ev = c("KM", "Cox", "RSF", "unif"))
print(res33$perf_test)

# In terms of quadratic, the best weights are the Cox weights
# remark : in this example there is not a big difference between the "unif" weights
# and the other weights because there is little censoring in the data :
res33$cens_rate

# -----------------------------------------------------------------
#     Try wRF2  and wRF3 (both are obtained with
#               \\code{mode_sw_RF = 2})
# -----------------------------------------------------------------

res40 = sw_reg(y_var = "futime",
                                     delta_var = "delta",
                                     x_vars = setdiff(colnames(transplant_bis),
                                                      c("futime", "delta", "event")),
                                     train = transplant_bis[train_lines,],
                                     test = transplant_bis[-train_lines,],
                                     type_w = "Cox",
                                     max_time = 600, # we set \\code{max_time} to 600
                                     types_w_ev = c("KM", "Cox", "RSF", "unif"),
                                     mode_sw_RF = 2)
print(res40$perf_test) # wRF2 : not as good as wRF1
print(res40$perf_test_KMloc) # wRF3 : worse than wRF2


# -------------------------------------------------------
#               Try a GAM model
# -------------------------------------------------------

## GLM with Cox weights
res5 = sw_reg(y_var = "futime",
                                     delta_var = "delta",
                                     x_vars = setdiff(colnames(transplant_bis),
                                                      c("futime", "delta", "event")),
                                     train = transplant_bis[train_lines,],
                                     test = transplant_bis[-train_lines,],
                                     type_w = "Cox",
                                     max_time = 600, # we set \\code{max_time} to 600
                                     types_w_ev = c("KM", "Cox", "RSF", "unif"),
                                    type_reg = "gam")
print(res5$perf_test) # not as good as random forest


# ------------------------------------------------------------
#     Analyse the weights used for "weighted" criteria
# ------------------------------------------------------------

print(res31$cens_rate) # rate of censoring taking into account \\code{max_time}
print(head(res31$mat_w_test))
## ratio max(weights)/min(weights)
print(apply(X = res31$mat_w_test,
            MARGIN = 2,
            FUN = function(x){max(x[x != 0])/min(x[x != 0])}))
# ratios are low because the censoring rate is low

# in this case, it is not meaningful to to modify the
# \\code{max_w_ev} argument since the maximum ratios
# between weights are around 2 and the test data has 197 rows.
# But in other situation it may be pertinent


# ------------------------------------------------
#   Use custom \\code{phi} function
# ------------------------------------------------
g = function(x,a) abs(x-a)
set.seed(17)
train_lines = sample(1:nrow(transplant_bis), 600)
res6 = sw_reg(y_var = "futime",
                                    delta_var = "delta",
                                    x_vars = setdiff(colnames(transplant_bis),
                                                     c("futime", "delta", "event")),
                                    train = transplant_bis[train_lines,],
                                    test = transplant_bis[-train_lines,],
                                    phi = g,
                                    phi.args = list(a = 200),
                                    type_w = "Cox",
                                    max_time = 600, # we set \\code{max_time} to 600
                                    types_w_ev = c("KM", "Cox", "RSF", "unif"))
print(res6$perf_test) # slight improvment compared with weights KM
}
\references{
Gerber, G., Le Faou, Y., Lopez, O., & Trupin, M. (2018). \emph{The impact of churn on
prospect value in health insurance, evaluation using a random forest under random censoring.}
\url{https://hal.archives-ouvertes.fr/hal-01807623/}
}
\seealso{
\code{\link[randomForestSRC]{rfsrc}}, \code{\link[rpart]{rpart}},
\code{\link[mgcv]{gam}},
\code{\link{predict_sw_reg}}
}
